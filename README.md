# Barnacle Detection Pipeline

## Overview

This repository implements an image-based barnacle detection pipeline. The project steps are as follows:

1. **Preprocessing**: This step perfroms basic input validation and loads images into the *ImageLoader* class. 

2. **Frame Extraction**: Here, the processed images are fed through a series of filters: a HSV (hue-saturation-value) color filter and a RGB color filter. These isolate the dark green wireframe (and do nothing if the image was taken without the frame). Next, a flood fill algorithm is used to identify the pixel region representing the interior of the frame. The original image is then cropped to contain only the interior region of interest for classification.  

3. **Detection**: Finally, the *BarnacleDetector* class uses a GaussianBlur and circle fitting approach with customized parameters (Hough Circle Transform) to detect barnacles in the image. The detected areas are validated and then drawn onto the image. 

4. **Analysis**: A Jupyter notebook (`example.ipynb`) demonstrates results and demonstrates the *BarnaclePipeline* class. The README file also contains results, project thoughts, conclusions, and learnings. 

## Repository Structure
```
├── README.md
├── data
│   ├── img1.png
│   ├── img2.png
│   ├── ...
├── frames                      # created during excecution 
│   ├── frame_img1.png          # generated frame images
│   ├── frame_img2.png
│   ├── ... 
├── outputs                     # created during excecution 
│   ├── barnacles_img1.png      # generated labeled barnacle images
│   ├── barnacles_img2.png
│   ├── ...
├── plots
│   ├── img1_overview.svg       # created during excecution 
│   ├── img2_overview.svg       # generated barnacle pipeline plots
│   ├── ...
├── requirements.txt          
├── reset.sh                    # delete assets during excecution 
└── src
    ├── barnacle_detector.py
    ├── barnacle_pipeline.py
    ├── example.ipynb
    ├── frame_extractor.py
    ├── generate_plots.py
    ├── image_loader.py
    └── utils.py
```


* **`barnacle_detector.py`**
  Implements `BarnacleDetector`, configurable via parameters to detect circular shapes corresponding to barnacles.

* **`barnacle_pipeline.py`**
  Combines extraction, detection, and drawing in the `BarnaclePipeline` class. This high-level wrapper allows for the simple creation and operation of a working model. 

* **`example.ipynb`**
  A Jupyter notebook that walks through:

  * Setting up the pipeline
  * Running detection on sample data
  * Visualizing intermediate steps (blur, edge maps, detected circles)

* **`frame_extractor.py`**
  Defines `FrameExtractor`, which applies a series of image filters to isolate the interior of a green wireframe and stores the modified images.

* **`generate_plots.py`**
  Contains a helper function to generate display plots showcasing the orignal images, extracted frames, and outlined barnacles.

* **`image_loader.py`**
  Provides utility functions to read images from the disk and perform basic input validation/error handling.

* **`utils.py`**
  Contians a general-purpose helper function `save_image` used to save images created throughout the pipeline

* **`reset.sh`**
  Allows for files generated by the program to be quickly deleted. Includes safety checks as to not delete the project root or recursively run. This can be executed via
  ``` bash
  bash reset.sh
  ```


## Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/kiran-jones/barnacle-detection.git
   cd barnacle-detection
   ```

2. **Create and activate a virtual environment**

   ```bash
   python3 -m venv .venv
   source venv/bin/activate      
   # Windows: venv\Scripts\activate
   ```

3. **Install required dependencies**

   ```bash
   pip install -r requirements.txt
   ```
## Usage

### 1. Run the Detection Pipeline (CLI)

```bash
cd src
python3 barnacle_pipeline.py \
  --input_image_directory data \
  --output_image_directory outputs \
  --frame_image_directory frames  \
  --log True
```

This will:

* Isolate the interior of the wireframe for each image in `data`
    * If an image has no wireframe it will use the full image  
* Save the frame cut-outs to `frames`
* Detect barnacle-like circles in each frame.
* Draw outlines on the images cooresponding to each detected barnacle. 
* Save the modified images to to `outputs`.
* Log status messages to stdout throughout the process. 

### 2. Interactive Exploration (Jupyter)

1. Launch Jupyter:

   ```bash
   jupyter notebook example.ipynb
   ```
2. Follow the notebook cells to:

   * Load sample data
   * Inspect preprocessing steps
   * Tune detector parameters
   * Visualize final detection overlays

## Results
![Plot1](plots/img1_overview.svg)
![Plot2](plots/img2_overview.svg)
![UnseenPlot1](plots/unseen_img1_overview.svg)
![UnseenPlot2](plots/unseen_img2_overview.svg)

## Process Thoughts 
One of the largest challenges I faced trying to solve this problem was the provided data. The specifications only provided four sample images containing barnacles, each differing in dimensionality, contrast, and barnacle coloring. This limitation shaped my solution, as I opted for a traditional computer vision approach as opposed to a more technically intricate model. 

While I considered using a machine learning based approach, I decided that it would be overkill and not optimal given the context of this problem and with the provided data. While acheiving a high classification accuracy would likley be possible, doing so would likley require a significant amount of data generation (altering patches of barnacles to create new, different examples) and would be very difficult to do without overfitting. 

I divided the classification problem into two subtasks: identifying the interior of the wireframe in an image and classifying barnacles located within the wirefranme. 

As  displayed in the charts above, I first used a series of image processing techniques to isolate the wireframe from the rest of the image. I then ran a flood fill algorithm on the modified image to determine which pixels lie within the largest interior circle. Finally, I isolated this region in the original image, yeilding the interior frame of interest. These pictures are visible as the middle image in the charts above. The code for this step is located in *frame_extractor.py*

With the interior cutout, I then used a Hough Circle Transform to extract features resembling barnacles as represented in the four provided images. This algorithm uses a series of parameters to influence its search space and sensitivity. I iteratively tested different combinations of these values, tuning them to optimize for accuracy across the four provided images. As shown in the charts above, the fine-tuned algorithm preforms respectably, especially given its simplicity and training data. The code for this process can be found in *barnacle_detector.py* 


## Conclusions

The first stage of the project (interior wireframe frame extraction) words extremely well. In each of the examples, the process correctly identifies and isolates the region of interest for barnacle counting. As implemented in this project, the Hough Circle approach reliably detects the majority of barnacles in a provided image. However, due to the limited data it works on the examples it was created using and performence may drop on new images it has not been optimized for. Furthermore, it does not correctly identify every single barnacle in any of the images - evidence that the pipeline should not be used on its own to produce a definitive count of barnacles. 

If the barnacle count does not need to be fully accurate, this model could serve as a good ballpark estimate. In each of the provided images, the model correctly classified ~90-95% of barnacles. Considering the highly efficient runtime of the classifier, this could serve as an estimation tool to quickly provide population approximations. 

If a fully accurate count is needed, the labeled images could also be given to humans for manual verification, as the relatively few errors (both false positives and unlabeled barnacles) can be counted much faster than the entire population from an unlabed image. This could provide an efficient method for human-suppoerted counting producing fully accurate results, or $C = L - F_P + F_N$ where $C$ is the accurate barnacle count, $L$ is the amount of labeled barnacles from the model, $F_P$ is the number of false positives, and $F_N$ is the number of false negatives. This way, the model does the heavy lifting and humans can clean up any ambiguity to produce an accurate, reliable count. 

If more data were avaliable in the future to train a machine learning based model on, the first step of the classifier (interior frame extractor) could still provide value, as it efficiently isolates the area of interest. These isolated frames could be used to for further training. 


## Learnings

For this project, I learned how to use OpenCV and about computer vision. I had never used CV algorithms before, and ended up reseaching many different routes which I didn't end up using in this project. Some of these include `findContours`, `SimpleBlobDetector`, `Watershed`, and `distanceTransform`. I did not expect to enjoy playing with these different approaches and reading image documentation as much as I did. I found the mathematical elegance of these approaches realy interesting - while more complicated machine learning methods rely on high-dimensional concepts such as tokenization and attention these CV algorithms utilize traditional matrix operations and work with remarkable accuracy. Furthermore, they avoid the need to perform computationally expensive training and run very effeciently. While they are not the right solution to every classification problem, they should not be overlooked and can be very performant when properly utilized. 


---

